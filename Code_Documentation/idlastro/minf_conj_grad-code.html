<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<!-- Generated by IDLdoc 3.5.1 on Mon Sep 30 16:57:47 2013 -->

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
    <title>minf_conj_grad.pro (Documentation for ./)</title>

    
    <link rel="stylesheet" type="text/css" media="all"
          href="../idldoc-resources/main.css" />
    <link rel="stylesheet" type="text/css" media="print"
          href="../idldoc-resources/main-print.css" />
    

    <script type="text/javascript">
      function setTitle() {
        parent.document.title="minf_conj_grad.pro (Documentation for ./)";
      }
    </script>
  </head>

  <body onload="setTitle();" id="root">
    <div class="content">
      <code class="source"><a id="minF_conj_grad:source"></a>pro minF_conj_grad, p_min, f_min, conv_factor, FUNC_NAME=func_name, $
                                        TOLERANCE=tol, USE_DERIV=use, $
                                        INITIALIZE=initialize, QUADRATIC=quad
<span class="comments">;+</span>
<span class="comments">; NAME:</span>
<span class="comments">;        MINF_CONJ_GRAD</span>
<span class="comments">; PURPOSE:</span>
<span class="comments">;       Find the local minimum of a scalar function using conjugate gradient</span>
<span class="comments">; EXPLANATION:</span>
<span class="comments">;       Find the local minimum of a scalar function of several variables using </span>
<span class="comments">;       the Conjugate Gradient method (Fletcher-Reeves-Polak-Ribiere algorithm).</span>
<span class="comments">;       Function may be anything with computable partial derivatives.</span>
<span class="comments">;       Each call to minF_conj_grad performs one iteration of algorithm,</span>
<span class="comments">;       and returns an N-dim point closer to the local minimum of function.</span>
<span class="comments">; CALLING EXAMPLE:</span>
<span class="comments">;       p_min = replicate( 1, N_dim )</span>
<span class="comments">;       minF_conj_grad, p_min, f_min, conv_factor, FUNC_NAME="name",/INITIALIZE</span>
<span class="comments">;</span>
<span class="comments">;       while (conv_factor GT 0) do begin</span>
<span class="comments">;               minF_conj_grad, p_min, f_min, conv_factor, FUNC_NAME="name"</span>
<span class="comments">;       endwhile</span>
<span class="comments">; INPUTS:</span>
<span class="comments">;       p_min = vector of independent variables, location of minimum point</span>
<span class="comments">;               obtained from previous call to minF_conj_grad, (or first guess).</span>
<span class="comments">; KEYWORDS:</span>
<span class="comments">;       FUNC_NAME = function name (string)</span>
<span class="comments">;               Calling mechanism should be:  F = func_name( px, gradient )</span>
<span class="comments">;         where:</span>
<span class="comments">;               F = scalar value of function at px.</span>
<span class="comments">;               px = vector of independent variables, input.</span>
<span class="comments">;               gradient = vector of partial derivatives of the function</span>
<span class="comments">;                       with respect to independent variables, evaluated at px.</span>
<span class="comments">;                       This is an optional output parameter:</span>
<span class="comments">;                       gradient should not be calculated if parameter is not</span>
<span class="comments">;                       supplied in call (Unless you want to waste some time).</span>
<span class="comments">;      /INIT must be specified on first call (whenever p_min is a guess),</span>
<span class="comments">;                       to initialize the iteration scheme of algorithm.</span>
<span class="comments">;      /USE_DERIV causes the directional derivative of function to be used</span>
<span class="comments">;                       in the 1-D minimization part of algorithm</span>
<span class="comments">;                       (default is not to use directional derivative).</span>
<span class="comments">;       TOLERANCE = desired accuracy of minimum location, default=sqrt(1.e-7).</span>
<span class="comments">;      /QUADRATIC runs simpler version which works only for quadratic function.</span>
<span class="comments">; OUTPUTS:</span>
<span class="comments">;       p_min = vector giving improved solution for location of minimum point.</span>
<span class="comments">;       f_min = value of function at p_min.</span>
<span class="comments">;       conv_factor = gives the current rate of convergence (change in value),</span>
<span class="comments">;                       iteration should be stopped when rate gets near zero.</span>
<span class="comments">; EXTERNAL CALLS:</span>
<span class="comments">;       pro minF_bracket,  to find 3 points which bracket the minimum in 1-D.</span>
<span class="comments">;       pro minF_parabolic,  to find minimum point in 1-D.</span>
<span class="comments">;       pro minF_parabol_D,  to find minimum point in 1-D, using derivatives.</span>
<span class="comments">; COMMON BLOCKS:</span>
<span class="comments">;       common minf_conj_grad, grad_conj, grad_save, gs_norm</span>
<span class="comments">;       (to keep conjugate gradient, gradient and norm from previous iteration)</span>
<span class="comments">; PROCEDURE:</span>
<span class="comments">;       Algorithm adapted from Numerical Recipes, sec.10.6 (p.305).</span>
<span class="comments">;       Conjugate gradient is computed from gradient, which then gives</span>
<span class="comments">;       the best direction (in N-dim space) in which to proceed to find</span>
<span class="comments">;       the minimum point. The function is then minimized along</span>
<span class="comments">;       this direction of conjugate gradient (a 1-D minimization).</span>
<span class="comments">;       The algorithm is repeated starting at the new point by calling again.</span>
<span class="comments">; MODIFICATION HISTORY:</span>
<span class="comments">;       Written, Frank Varosi NASA/GSFC 1992.</span>
<span class="comments">;       Converted to IDL V5.0   W. Landsman   September 1997</span>
<span class="comments">;-</span>
 On_error,2 
 
 if N_params() LT 3 then begin  
   print,'Syntax - minF_conj_grad, p_min, f_min, conv_factor, FUNC_NAME = 
   print,'         [ TOLERANCE=, USE_DERIV=, INITIALIZE= , QUADRATIC= ]
   return
 endif

  common minf_conj_grad, grad_conj, grad_save, gs_norm

        fp = call_function( func_name, p_min, gradient )

<span class="comments">;Compute conjugate gradient direction:</span>

        if keyword_set( initialize ) then begin

                grad_conj = -gradient
                gs_norm = total( gradient * gradient )
                if NOT keyword_set( quad ) then grad_save = gradient

          endif else begin

                grad_norm = total( gradient * gradient )

                if (grad_norm EQ 0) then begin
                        f_min = fp
                        conv_factor = 0
                        return
                   endif

                if keyword_set( quad ) then gamma = grad_norm/gs_norm else begin

                    gamma = ( grad_norm - total( grad_save*gradient ) )/gs_norm
                        grad_save = gradient
                  endelse

                grad_conj = gamma * grad_conj - gradient
                gs_norm = grad_norm
           endelse

<span class="comments">;Now find miminum along direction of conjugate gradient:</span>

        xa = 0
        xb = 1/sqrt( gs_norm )

        minF_bracket, xa,xb,xc, fa,fb,fc, FUNC_NAME=func_name, POINT=p_min, $
                                                        DIRECTION=grad_conj
        if keyword_set( use ) then begin

                minF_parabol_D, xa,xb,xc, x_min, f_min, FUN=func_name, TOL=tol,$
                                                POINT=p_min, DIRECTION=grad_conj
          endif else begin

                minF_parabolic, xa,xb,xc, x_min, f_min, FUN=func_name, TOL=tol,$
                                                POINT=p_min, DIRECTION=grad_conj
           endelse

        conv_factor = 2*abs( f_min - fp )/( (abs(f_min) + abs(fp)) > 1.e-9 )

        p_min = p_min + x_min * grad_conj
return
end
</code>
    </div>
  </body>
</html>